{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\repos\\701-simplicity-bias\n"
     ]
    }
   ],
   "source": [
    "# go to the root directory\n",
    "%cd../\n",
    "import os\n",
    "\n",
    "assert os.path.exists('./trainers/trainer.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import generate_fcn\n",
    "from trainers import Trainer\n",
    "from synthetic_data.linear_slabs import load_arrays\n",
    "import datetime\n",
    "from logging import Logger, StreamHandler"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# follow the config of original paper\n",
    "\n",
    "model_config = dict(\n",
    "    num_layers=2,\n",
    "    input_dim=50,\n",
    "    output_dim=2,\n",
    "    latent_dim=100,\n",
    "    use_bn=False,\n",
    "    dropout_probability=0.0,\n",
    "    linear_init=None\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=50, out_features=100, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=100, out_features=100, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=100, out_features=2, bias=True)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_fcn(**model_config)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# use lms_7_noisy\n",
    "train_data, w = load_arrays('./data/lms_7_noisy_train.npz')\n",
    "val_data, _ = load_arrays('./data/lms_7_noisy_val.npz')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model: Sequential(\n",
      "  (0): Linear(in_features=50, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=100, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer_logger = Logger('trainer')\n",
    "trainer_logger.setLevel('DEBUG')\n",
    "trainer_logger.addHandler(StreamHandler())\n",
    "trainer_config = dict(\n",
    "    train_data=dict(\n",
    "        dataset=train_data,\n",
    "        batch_size=256,\n",
    "        shuffle=True\n",
    "    ), val_data=dict(\n",
    "        dataset=val_data,\n",
    "        batch_size=256,\n",
    "        shuffle=False\n",
    "    ),\n",
    "    model=model,\n",
    "    loss=torch.nn.CrossEntropyLoss(),\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    evaluate_interval=500,\n",
    "    save_interval=0,\n",
    "    work_dir='./training_logs/lms7_noisy_{}/'.format(datetime.datetime.now().strftime('%m%d%H%M')),\n",
    "    loss_eps=1e-2,\n",
    "    logger=trainer_logger,\n",
    "    max_steps=100000,\n",
    "    optimizer=dict(\n",
    "        cls='SGD',\n",
    "        lr=0.1,\n",
    "        weight_decay=5.0e-5\n",
    "    )\n",
    ")\n",
    "trainer = Trainer(**trainer_config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 0: Loss 0.0005062478012405336\n",
      "Evaluating ...\n",
      "Step: 0\n",
      "Train/SumLoss: 0.18283148643240565\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3493556591565721\n",
      "Val/Accuracy: 0.9963\n",
      "Step 500: Loss 0.00047561159590259194\n",
      "Evaluating ...\n",
      "Step: 500\n",
      "Train/SumLoss: 0.18305313852033578\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34945420126314275\n",
      "Val/Accuracy: 0.9962\n",
      "Step 1000: Loss 0.000320620572892949\n",
      "Evaluating ...\n",
      "Step: 1000\n",
      "Train/SumLoss: 0.18405432988947723\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3755307869578246\n",
      "Val/Accuracy: 0.9961\n",
      "Step 1500: Loss 0.0009318586671724916\n",
      "Evaluating ...\n",
      "Step: 1500\n",
      "Train/SumLoss: 0.18406245238293195\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3341936993820127\n",
      "Val/Accuracy: 0.9963\n",
      "Step 2000: Loss 0.00018836009257938713\n",
      "Evaluating ...\n",
      "Step: 2000\n",
      "Train/SumLoss: 0.17863637276605004\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34617872221861035\n",
      "Val/Accuracy: 0.9962\n",
      "Step 2500: Loss 0.0003685743431560695\n",
      "Evaluating ...\n",
      "Step: 2500\n",
      "Train/SumLoss: 0.17727507303789025\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3573420953762252\n",
      "Val/Accuracy: 0.996\n",
      "Step 3000: Loss 0.0006095399148762226\n",
      "Evaluating ...\n",
      "Step: 3000\n",
      "Train/SumLoss: 0.17588773972238414\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.35203338092105696\n",
      "Val/Accuracy: 0.9963\n",
      "Step 3500: Loss 0.00063348124967888\n",
      "Evaluating ...\n",
      "Step: 3500\n",
      "Train/SumLoss: 0.1764452132556471\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3658019671420334\n",
      "Val/Accuracy: 0.9962\n",
      "Step 4000: Loss 0.0004413517308421433\n",
      "Evaluating ...\n",
      "Step: 4000\n",
      "Train/SumLoss: 0.17681206455017673\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33532746077980846\n",
      "Val/Accuracy: 0.9965\n",
      "Step 4500: Loss 0.000371556612662971\n",
      "Evaluating ...\n",
      "Step: 4500\n",
      "Train/SumLoss: 0.1737732450128533\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.35421573020721553\n",
      "Val/Accuracy: 0.9961\n",
      "Step 5000: Loss 0.00029945350252091885\n",
      "Evaluating ...\n",
      "Step: 5000\n",
      "Train/SumLoss: 0.17599187583982712\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.36837634874973446\n",
      "Val/Accuracy: 0.9963\n",
      "Step 5500: Loss 0.0005154327373020351\n",
      "Evaluating ...\n",
      "Step: 5500\n",
      "Train/SumLoss: 0.17347736074589193\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3444298101385357\n",
      "Val/Accuracy: 0.9963\n",
      "Step 6000: Loss 0.0007301844307221472\n",
      "Evaluating ...\n",
      "Step: 6000\n",
      "Train/SumLoss: 0.17248996822308982\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.362180945907312\n",
      "Val/Accuracy: 0.9962\n",
      "Step 6500: Loss 8.286611409857869e-05\n",
      "Evaluating ...\n",
      "Step: 6500\n",
      "Train/SumLoss: 0.17361722417990677\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3616972816816997\n",
      "Val/Accuracy: 0.996\n",
      "Step 7000: Loss 0.0006410978967323899\n",
      "Evaluating ...\n",
      "Step: 7000\n",
      "Train/SumLoss: 0.17337983062316198\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3343807551354985\n",
      "Val/Accuracy: 0.9965\n",
      "Step 7500: Loss 0.00036427227314561605\n",
      "Evaluating ...\n",
      "Step: 7500\n",
      "Train/SumLoss: 0.17034726915881038\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3392295244993875\n",
      "Val/Accuracy: 0.9962\n",
      "Step 8000: Loss 0.00033711697324179113\n",
      "Evaluating ...\n",
      "Step: 8000\n",
      "Train/SumLoss: 0.17274928060214734\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.368295671112719\n",
      "Val/Accuracy: 0.9961\n",
      "Step 8500: Loss 0.0003786161250900477\n",
      "Evaluating ...\n",
      "Step: 8500\n",
      "Train/SumLoss: 0.16952998744818615\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3583171276259236\n",
      "Val/Accuracy: 0.9962\n",
      "Step 9000: Loss 0.0006409757770597935\n",
      "Evaluating ...\n",
      "Step: 9000\n",
      "Train/SumLoss: 0.17006140753801446\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3627180358816986\n",
      "Val/Accuracy: 0.9962\n",
      "Step 9500: Loss 0.0005658903974108398\n",
      "Evaluating ...\n",
      "Step: 9500\n",
      "Train/SumLoss: 0.16733724745427025\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.344341810712649\n",
      "Val/Accuracy: 0.9963\n",
      "Step 10000: Loss 0.00029848856502212584\n",
      "Evaluating ...\n",
      "Step: 10000\n",
      "Train/SumLoss: 0.16680694800743368\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34774047412065556\n",
      "Val/Accuracy: 0.9962\n",
      "Step 10500: Loss 0.00047953243483789265\n",
      "Evaluating ...\n",
      "Step: 10500\n",
      "Train/SumLoss: 0.16625078188371845\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3395612188469386\n",
      "Val/Accuracy: 0.9963\n",
      "Step 11000: Loss 0.0005098222172819078\n",
      "Evaluating ...\n",
      "Step: 11000\n",
      "Train/SumLoss: 0.16962702690943843\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32699428175692447\n",
      "Val/Accuracy: 0.9966\n",
      "Step 11500: Loss 0.0004790032980963588\n",
      "Evaluating ...\n",
      "Step: 11500\n",
      "Train/SumLoss: 0.16568310877482872\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33601225772872567\n",
      "Val/Accuracy: 0.9963\n",
      "Step 12000: Loss 0.00048191609675996006\n",
      "Evaluating ...\n",
      "Step: 12000\n",
      "Train/SumLoss: 0.17512339664244791\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.38621352256450336\n",
      "Val/Accuracy: 0.9959\n",
      "Step 12500: Loss 0.00042526997276581824\n",
      "Evaluating ...\n",
      "Step: 12500\n",
      "Train/SumLoss: 0.1636799745465396\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3464095778108458\n",
      "Val/Accuracy: 0.9962\n",
      "Step 13000: Loss 0.00035999491228722036\n",
      "Evaluating ...\n",
      "Step: 13000\n",
      "Train/SumLoss: 0.1718072515723179\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.37447018903912976\n",
      "Val/Accuracy: 0.9963\n",
      "Step 13500: Loss 0.0008045203285291791\n",
      "Evaluating ...\n",
      "Step: 13500\n",
      "Train/SumLoss: 0.1776282652062946\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3078153316891985\n",
      "Val/Accuracy: 0.9968\n",
      "Step 14000: Loss 0.0005495972582139075\n",
      "Evaluating ...\n",
      "Step: 14000\n",
      "Train/SumLoss: 0.16328909544608905\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3483307486458216\n",
      "Val/Accuracy: 0.9962\n",
      "Step 14500: Loss 0.00024080611183308065\n",
      "Evaluating ...\n",
      "Step: 14500\n",
      "Train/SumLoss: 0.16456689606275177\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3586366564122727\n",
      "Val/Accuracy: 0.9961\n",
      "Step 15000: Loss 0.00028079928597435355\n",
      "Evaluating ...\n",
      "Step: 15000\n",
      "Train/SumLoss: 0.1629407069485751\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3395924402284436\n",
      "Val/Accuracy: 0.9961\n",
      "Step 15500: Loss 0.00021395416115410626\n",
      "Evaluating ...\n",
      "Step: 15500\n",
      "Train/SumLoss: 0.1656064696944668\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.36196256711991737\n",
      "Val/Accuracy: 0.9961\n",
      "Step 16000: Loss 0.0009419930283911526\n",
      "Evaluating ...\n",
      "Step: 16000\n",
      "Train/SumLoss: 0.16831661144897225\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31468074207077734\n",
      "Val/Accuracy: 0.9968\n",
      "Step 16500: Loss 0.00023953523486852646\n",
      "Evaluating ...\n",
      "Step: 16500\n",
      "Train/SumLoss: 0.16660823705024086\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.36722035841376055\n",
      "Val/Accuracy: 0.996\n",
      "Step 17000: Loss 0.0005104612209834158\n",
      "Evaluating ...\n",
      "Step: 17000\n",
      "Train/SumLoss: 0.16133343509864062\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33988440892426297\n",
      "Val/Accuracy: 0.9964\n",
      "Step 17500: Loss 0.0004356104473117739\n",
      "Evaluating ...\n",
      "Step: 17500\n",
      "Train/SumLoss: 0.16308309552550782\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32109767891233787\n",
      "Val/Accuracy: 0.9964\n",
      "Step 18000: Loss 0.00016828214575070888\n",
      "Evaluating ...\n",
      "Step: 18000\n",
      "Train/SumLoss: 0.16044178525044117\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3422320526733529\n",
      "Val/Accuracy: 0.9962\n",
      "Step 18500: Loss 0.00042641672189347446\n",
      "Evaluating ...\n",
      "Step: 18500\n",
      "Train/SumLoss: 0.16276776262748172\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3233356205309974\n",
      "Val/Accuracy: 0.9963\n",
      "Step 19000: Loss 0.000737588619813323\n",
      "Evaluating ...\n",
      "Step: 19000\n",
      "Train/SumLoss: 0.15971133737184573\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33809948786802124\n",
      "Val/Accuracy: 0.9963\n",
      "Step 19500: Loss 0.00038354701246134937\n",
      "Evaluating ...\n",
      "Step: 19500\n",
      "Train/SumLoss: 0.1605487892011297\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3237581129797036\n",
      "Val/Accuracy: 0.9963\n",
      "Step 20000: Loss 0.00014851201558485627\n",
      "Evaluating ...\n",
      "Step: 20000\n",
      "Train/SumLoss: 0.16533907308621565\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3666036978538614\n",
      "Val/Accuracy: 0.9963\n",
      "Step 20500: Loss 0.00045438887900672853\n",
      "Evaluating ...\n",
      "Step: 20500\n",
      "Train/SumLoss: 0.1621827038252377\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.36034871364972787\n",
      "Val/Accuracy: 0.9962\n",
      "Step 21000: Loss 0.00020852574380114675\n",
      "Evaluating ...\n",
      "Step: 21000\n",
      "Train/SumLoss: 0.15856638758123154\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3401395467008115\n",
      "Val/Accuracy: 0.9964\n",
      "Step 21500: Loss 0.00021726658451370895\n",
      "Evaluating ...\n",
      "Step: 21500\n",
      "Train/SumLoss: 0.16219032312073978\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3132432167767547\n",
      "Val/Accuracy: 0.9968\n",
      "Step 22000: Loss 0.0009546212968416512\n",
      "Evaluating ...\n",
      "Step: 22000\n",
      "Train/SumLoss: 0.16151251463452354\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31601832775049843\n",
      "Val/Accuracy: 0.9965\n",
      "Step 22500: Loss 0.0004191818879917264\n",
      "Evaluating ...\n",
      "Step: 22500\n",
      "Train/SumLoss: 0.16001994711405132\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34739349324809154\n",
      "Val/Accuracy: 0.9964\n",
      "Step 23000: Loss 0.0005437140935100615\n",
      "Evaluating ...\n",
      "Step: 23000\n",
      "Train/SumLoss: 0.1579235634417273\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.331238336097158\n",
      "Val/Accuracy: 0.9965\n",
      "Step 23500: Loss 0.0003676762862596661\n",
      "Evaluating ...\n",
      "Step: 23500\n",
      "Train/SumLoss: 0.15810268368659308\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33548368000629125\n",
      "Val/Accuracy: 0.9962\n",
      "Step 24000: Loss 0.0003537537413649261\n",
      "Evaluating ...\n",
      "Step: 24000\n",
      "Train/SumLoss: 0.16072872084623668\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31445135847025085\n",
      "Val/Accuracy: 0.9967\n",
      "Step 24500: Loss 0.0004245723830536008\n",
      "Evaluating ...\n",
      "Step: 24500\n",
      "Train/SumLoss: 0.15712789480312495\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33399299379379954\n",
      "Val/Accuracy: 0.9966\n",
      "Step 25000: Loss 0.00018916602130047977\n",
      "Evaluating ...\n",
      "Step: 25000\n",
      "Train/SumLoss: 0.15964474505744874\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34735296614235267\n",
      "Val/Accuracy: 0.9963\n",
      "Step 25500: Loss 0.0005882259574718773\n",
      "Evaluating ...\n",
      "Step: 25500\n",
      "Train/SumLoss: 0.15801554232166382\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3258977409568615\n",
      "Val/Accuracy: 0.9966\n",
      "Step 26000: Loss 0.0005259281024336815\n",
      "Evaluating ...\n",
      "Step: 26000\n",
      "Train/SumLoss: 0.1574867958552204\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32418902797508053\n",
      "Val/Accuracy: 0.9964\n",
      "Step 26500: Loss 0.0002783470554277301\n",
      "Evaluating ...\n",
      "Step: 26500\n",
      "Train/SumLoss: 0.16532912830734858\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.30652291743899696\n",
      "Val/Accuracy: 0.9967\n",
      "Step 27000: Loss 0.00035251735243946314\n",
      "Evaluating ...\n",
      "Step: 27000\n",
      "Train/SumLoss: 0.1590937224245863\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31506407604319975\n",
      "Val/Accuracy: 0.9966\n",
      "Step 27500: Loss 0.0007625584257766604\n",
      "Evaluating ...\n",
      "Step: 27500\n",
      "Train/SumLoss: 0.15728909309837036\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3376449966453947\n",
      "Val/Accuracy: 0.9966\n",
      "Step 28000: Loss 0.00023472106840927154\n",
      "Evaluating ...\n",
      "Step: 28000\n",
      "Train/SumLoss: 0.15677935307030566\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3206989828613587\n",
      "Val/Accuracy: 0.9964\n",
      "Step 28500: Loss 0.00044668957707472146\n",
      "Evaluating ...\n",
      "Step: 28500\n",
      "Train/SumLoss: 0.15634425479220226\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3190827883372549\n",
      "Val/Accuracy: 0.9967\n",
      "Step 29000: Loss 0.0003693208273034543\n",
      "Evaluating ...\n",
      "Step: 29000\n",
      "Train/SumLoss: 0.15657166534947464\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33337391512759496\n",
      "Val/Accuracy: 0.9966\n",
      "Step 29500: Loss 0.00015593486023135483\n",
      "Evaluating ...\n",
      "Step: 29500\n",
      "Train/SumLoss: 0.15699655110074673\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33741530164843425\n",
      "Val/Accuracy: 0.9964\n",
      "Step 30000: Loss 0.0002933150390163064\n",
      "Evaluating ...\n",
      "Step: 30000\n",
      "Train/SumLoss: 0.15590480688842945\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31745782468351535\n",
      "Val/Accuracy: 0.9967\n",
      "Step 30500: Loss 0.000655829266179353\n",
      "Evaluating ...\n",
      "Step: 30500\n",
      "Train/SumLoss: 0.15539740944223013\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3308440133841941\n",
      "Val/Accuracy: 0.9963\n",
      "Step 31000: Loss 0.0005578138516284525\n",
      "Evaluating ...\n",
      "Step: 31000\n",
      "Train/SumLoss: 0.1554979977227049\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32278053257323336\n",
      "Val/Accuracy: 0.9966\n",
      "Step 31500: Loss 0.0003801280981861055\n",
      "Evaluating ...\n",
      "Step: 31500\n",
      "Train/SumLoss: 0.15876005055906717\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3094878936826717\n",
      "Val/Accuracy: 0.9967\n",
      "Step 32000: Loss 0.00072292989352718\n",
      "Evaluating ...\n",
      "Step: 32000\n",
      "Train/SumLoss: 0.15761845003726194\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3097293431055732\n",
      "Val/Accuracy: 0.9966\n",
      "Step 32500: Loss 0.0004209602775517851\n",
      "Evaluating ...\n",
      "Step: 32500\n",
      "Train/SumLoss: 0.157407894890639\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3094947130593937\n",
      "Val/Accuracy: 0.9968\n",
      "Step 33000: Loss 0.0004797062720172107\n",
      "Evaluating ...\n",
      "Step: 33000\n",
      "Train/SumLoss: 0.1588298271635722\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3096175768150715\n",
      "Val/Accuracy: 0.997\n",
      "Step 33500: Loss 0.0003661969385575503\n",
      "Evaluating ...\n",
      "Step: 33500\n",
      "Train/SumLoss: 0.15495392820957932\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3287714158796007\n",
      "Val/Accuracy: 0.9964\n",
      "Step 34000: Loss 0.0004948596470057964\n",
      "Evaluating ...\n",
      "Step: 34000\n",
      "Train/SumLoss: 0.15471477625033003\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32250741188181564\n",
      "Val/Accuracy: 0.9966\n",
      "Step 34500: Loss 0.0002871445321943611\n",
      "Evaluating ...\n",
      "Step: 34500\n",
      "Train/SumLoss: 0.15511592212715186\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3258538292866433\n",
      "Val/Accuracy: 0.9966\n",
      "Step 35000: Loss 0.00043441817979328334\n",
      "Evaluating ...\n",
      "Step: 35000\n",
      "Train/SumLoss: 0.15898118755285395\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3052523051155731\n",
      "Val/Accuracy: 0.9969\n",
      "Step 35500: Loss 0.0004798996087629348\n",
      "Evaluating ...\n",
      "Step: 35500\n",
      "Train/SumLoss: 0.15481437246489804\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32958814516314305\n",
      "Val/Accuracy: 0.9965\n",
      "Step 36000: Loss 0.00014398203347809613\n",
      "Evaluating ...\n",
      "Step: 36000\n",
      "Train/SumLoss: 0.15458567915629828\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3290727633575443\n",
      "Val/Accuracy: 0.9965\n",
      "Step 36500: Loss 0.0007176347426138818\n",
      "Evaluating ...\n",
      "Step: 36500\n",
      "Train/SumLoss: 0.15480832880712114\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32229393501620507\n",
      "Val/Accuracy: 0.9964\n",
      "Step 37000: Loss 0.00035430811112746596\n",
      "Evaluating ...\n",
      "Step: 37000\n",
      "Train/SumLoss: 0.15636676325812005\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3105697007558774\n",
      "Val/Accuracy: 0.9965\n",
      "Step 37500: Loss 0.00041399343172088265\n",
      "Evaluating ...\n",
      "Step: 37500\n",
      "Train/SumLoss: 0.1605827995153959\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.301635662704939\n",
      "Val/Accuracy: 0.9964\n",
      "Step 38000: Loss 0.0003589325351640582\n",
      "Evaluating ...\n",
      "Step: 38000\n",
      "Train/SumLoss: 0.1605983536937856\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.35039396538195433\n",
      "Val/Accuracy: 0.9963\n",
      "Step 38500: Loss 0.00030410001636482775\n",
      "Evaluating ...\n",
      "Step: 38500\n",
      "Train/SumLoss: 0.15406575477391016\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33067833210225217\n",
      "Val/Accuracy: 0.9963\n",
      "Step 39000: Loss 0.0005476707010529935\n",
      "Evaluating ...\n",
      "Step: 39000\n",
      "Train/SumLoss: 0.15428776328917593\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31524039457872277\n",
      "Val/Accuracy: 0.9966\n",
      "Step 39500: Loss 0.0003921432071365416\n",
      "Evaluating ...\n",
      "Step: 39500\n",
      "Train/SumLoss: 0.1537929470614472\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3165935999568319\n",
      "Val/Accuracy: 0.9966\n",
      "Step 40000: Loss 0.0001331507519353181\n",
      "Evaluating ...\n",
      "Step: 40000\n",
      "Train/SumLoss: 0.155006073997356\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3290289803335327\n",
      "Val/Accuracy: 0.9964\n",
      "Step 40500: Loss 0.0002622100873850286\n",
      "Evaluating ...\n",
      "Step: 40500\n",
      "Train/SumLoss: 0.15828307198535185\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3441851797470008\n",
      "Val/Accuracy: 0.9963\n",
      "Step 41000: Loss 0.0003042752214241773\n",
      "Evaluating ...\n",
      "Step: 41000\n",
      "Train/SumLoss: 0.15367915418028133\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32232697043946246\n",
      "Val/Accuracy: 0.9964\n",
      "Step 41500: Loss 0.00022642873227596283\n",
      "Evaluating ...\n",
      "Step: 41500\n",
      "Train/SumLoss: 0.15518715968210017\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3369590538350167\n",
      "Val/Accuracy: 0.9964\n",
      "Step 42000: Loss 0.0002853965852409601\n",
      "Evaluating ...\n",
      "Step: 42000\n",
      "Train/SumLoss: 0.15365148897399195\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31820381522993557\n",
      "Val/Accuracy: 0.9964\n",
      "Step 42500: Loss 0.00034385002800263464\n",
      "Evaluating ...\n",
      "Step: 42500\n",
      "Train/SumLoss: 0.15484726917929947\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.33207155247509945\n",
      "Val/Accuracy: 0.9962\n",
      "Step 43000: Loss 0.00045155553380027413\n",
      "Evaluating ...\n",
      "Step: 43000\n",
      "Train/SumLoss: 0.15397013750043698\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3145940890390193\n",
      "Val/Accuracy: 0.9965\n",
      "Step 43500: Loss 0.000492281629703939\n",
      "Evaluating ...\n",
      "Step: 43500\n",
      "Train/SumLoss: 0.15734318188333418\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.30340132206038106\n",
      "Val/Accuracy: 0.997\n",
      "Step 44000: Loss 0.0005693722050637007\n",
      "Evaluating ...\n",
      "Step: 44000\n",
      "Train/SumLoss: 0.15388981395517476\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.31671356038714293\n",
      "Val/Accuracy: 0.9966\n",
      "Step 44500: Loss 0.0003212262818124145\n",
      "Evaluating ...\n",
      "Step: 44500\n",
      "Train/SumLoss: 0.16301259534520796\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.36273917109065223\n",
      "Val/Accuracy: 0.9961\n",
      "Step 45000: Loss 0.00045408925507217646\n",
      "Evaluating ...\n",
      "Step: 45000\n",
      "Train/SumLoss: 0.15362949891277822\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3293965271805064\n",
      "Val/Accuracy: 0.9965\n",
      "Step 45500: Loss 0.0005362635129131377\n",
      "Evaluating ...\n",
      "Step: 45500\n",
      "Train/SumLoss: 0.15337314788484946\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32733289804309607\n",
      "Val/Accuracy: 0.9964\n",
      "Step 46000: Loss 0.00045666826190426946\n",
      "Evaluating ...\n",
      "Step: 46000\n",
      "Train/SumLoss: 0.15340459656727035\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3193272536736913\n",
      "Val/Accuracy: 0.9967\n",
      "Step 46500: Loss 0.0003753943892661482\n",
      "Evaluating ...\n",
      "Step: 46500\n",
      "Train/SumLoss: 0.15370499451091746\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3311276288150111\n",
      "Val/Accuracy: 0.9963\n",
      "Step 47000: Loss 0.00033298181369900703\n",
      "Evaluating ...\n",
      "Step: 47000\n",
      "Train/SumLoss: 0.1539147040748503\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3117349722015206\n",
      "Val/Accuracy: 0.9965\n",
      "Step 47500: Loss 0.0001888695260277018\n",
      "Evaluating ...\n",
      "Step: 47500\n",
      "Train/SumLoss: 0.15353586125274887\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3231789565907093\n",
      "Val/Accuracy: 0.9964\n",
      "Step 48000: Loss 0.00018584090867079794\n",
      "Evaluating ...\n",
      "Step: 48000\n",
      "Train/SumLoss: 0.15373033551077242\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.32531147839472396\n",
      "Val/Accuracy: 0.9964\n",
      "Step 48500: Loss 0.00048739954945631325\n",
      "Evaluating ...\n",
      "Step: 48500\n",
      "Train/SumLoss: 0.15370676686870866\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3090963811991969\n",
      "Val/Accuracy: 0.9969\n",
      "Step 49000: Loss 0.00035252998350188136\n",
      "Evaluating ...\n",
      "Step: 49000\n",
      "Train/SumLoss: 0.15451337838021573\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3356441091236775\n",
      "Val/Accuracy: 0.9965\n",
      "Step 49500: Loss 0.00025687162997201085\n",
      "Evaluating ...\n",
      "Step: 49500\n",
      "Train/SumLoss: 0.15303682442754507\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3187620346143376\n",
      "Val/Accuracy: 0.9966\n",
      "Step 50000: Loss 0.00041025219252333045\n",
      "Evaluating ...\n",
      "Step: 50000\n",
      "Train/SumLoss: 0.15437613884569146\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.3089137110073352\n",
      "Val/Accuracy: 0.9964\n",
      "Step 50500: Loss 0.0004632188065443188\n",
      "Evaluating ...\n",
      "Step: 50500\n",
      "Train/SumLoss: 0.15820576943588094\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.29930626112036407\n",
      "Val/Accuracy: 0.997\n",
      "Step 51000: Loss 0.00034498271998018026\n",
      "Evaluating ...\n",
      "Step: 51000\n",
      "Train/SumLoss: 0.1557964426538092\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.34150905642309226\n",
      "Val/Accuracy: 0.9962\n",
      "Step 51500: Loss 0.0003003433521371335\n",
      "Evaluating ...\n",
      "Step: 51500\n",
      "Train/SumLoss: 0.16188341944507556\n",
      "Train/Accuracy: 1.0\n",
      "Val/SumLoss: 0.2920474377460778\n",
      "Val/Accuracy: 0.997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m trainer\u001B[38;5;241m.\u001B[39mrun()\n",
      "File \u001B[1;32mD:\\repos\\701-simplicity-bias\\trainers\\trainer.py:114\u001B[0m, in \u001B[0;36mTrainer.run\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stop:\n\u001B[0;32m    113\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x_batch, y_batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_data:\n\u001B[1;32m--> 114\u001B[0m         loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    115\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter\u001B[38;5;241m.\u001B[39madd_scalar(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain/Loss\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mitem(),\n\u001B[0;32m    116\u001B[0m                                global_step\u001B[38;5;241m=\u001B[39mstep)\n\u001B[0;32m    117\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_interval \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m step \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave_interval \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\repos\\701-simplicity-bias\\trainers\\trainer.py:63\u001B[0m, in \u001B[0;36mTrainer.train_step\u001B[1;34m(self, x_batch, y_batch)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     62\u001B[0m x_batch, y_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(x_batch, y_batch)\n\u001B[1;32m---> 63\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_batch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     64\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(logits, y_batch)\n\u001B[0;32m     65\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32mc:\\Users\\kevin\\anaconda3\\envs\\simplicity\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\Users\\kevin\\anaconda3\\envs\\simplicity\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mc:\\Users\\kevin\\anaconda3\\envs\\simplicity\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mc:\\Users\\kevin\\anaconda3\\envs\\simplicity\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
